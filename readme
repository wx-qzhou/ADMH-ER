Firstly, we try to generate all modal data based on pre-trained models.
1) Text : we obtain the form of representations, i.e., {"name" : representation}
2) Images : we obtain the form of representations, i.e., {"name" : representation}
3) Videos : we obtain the form of representations, i.e., {"name" : representation}

Secondly, we generate the ids of entities and relations.
entities : {entities' name : id}
relations : {relations' name : id}

Thirdly, we generate the classification labels and linking labels.
Note that, we create the groundtruth with the names.
For each name, we have four files, i.e., "xxx.class", "xxx.json" and "xxx.link"


## Datasets
The raw datasets can be found in \ref{}
