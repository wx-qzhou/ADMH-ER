Firstly, we try to generate all modal data based on pre-trained models.
1) Text : we obtain the form of representations, i.e., {"name" : representation}
2) Images : we obtain the form of representations, i.e., {"name" : representation}
3) Videos : we obtain the form of representations, i.e., {"name" : representation}

Secondly, we generate the ids of entities and relations.
entities : {entities' name : id}
relations : {relations' name : id}

Thirdly, we generate the classification labels and linking labels.
Note that, we create the groundtruth with the names.
For each name, we have four files, i.e., "xxx.class", "xxx.json" and "xxx.link"

---

## Datasets

The raw datasets can be found below.
### 1. DBP15k Datasets
It is available at the following GitHub repository:
- [EVA on GitHub](https://github.com/cambridgeltl/eva)

### 2. MMKB Datasets
It can be accessed via:
- [MMKG Dataset on GitHub](https://github.com/mniepert/mmkb)

### 3. Our processing Datasets
The rough datasets can be available. You can download it from:
- [MMER Datasets on AliPan](https://www.alipan.com/s/o7CG1cgqCfa)
